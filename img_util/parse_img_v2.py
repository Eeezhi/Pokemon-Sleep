import re
from datetime import datetime
import streamlit as st
import warnings; warnings.filterwarnings('ignore')
import requests
import os
import pandas as pd
import cv2
import numpy as np
from io import BytesIO

raw_DATA_DIR = os.path.join(os.path.dirname(__file__), "..", "data", "dbdata")

def get_db_item_list(collection_name: str):
    """ä» /data/dbdata ä¸‹çš„ CSV æ–‡ä»¶è¯»å–æ•°æ®"""
    file_path = os.path.join(raw_DATA_DIR, f"{collection_name}.csv")
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}")
    df = pd.read_csv(file_path)
    if "name" in df.columns:
        return df["name"].dropna().unique().tolist()
    else:
        return df.columns.tolist()

pokemons_list = get_db_item_list('airbyte_raw_Pokemon')
main_skills_list = get_db_item_list('airbyte_raw_MainSkill')
sub_skills_list = get_db_item_list('airbyte_raw_SubSkill')
natures_list = get_db_item_list('airbyte_raw_Nature')
ingredient_list = get_db_item_list('airbyte_raw_Ingredient')

# Free OCR API é…ç½®
OCR_PAYLOAD = {
    "isOverlayRequired": False,
    "apikey": "K87144738488957",
    "language": "cht",
    "isTable": True,  # å¯ç”¨è¡¨æ ¼è¯†åˆ«
}
OCR_ENDPOINT = "https://api.ocr.space/parse/image"

# ==================== è¾…åŠ©å‡½æ•° ====================

def correct_ocr_text(text):
    """åº”ç”¨OCRæ–‡å­—ä¿®æ­£è§„åˆ™"""
    if not isinstance(text, str):
        return text
    
    corrections = {
        'p537': '',
        'P310': '',
        'p756': '',
        'LV.IO': 'Lv.10',
        'æ¯42åˆ†33ç§’': '',
        'æ¯1å°æ™‚': '',
        # æ–‡å­—å¼‚ä½“å­—ç»Ÿä¸€ï¼ˆOCRæ˜“è¯†åˆ«ä¸ºæ—¥æ–‡/ç®€ä½“å¼‚ä½“ï¼‰
        'å‘‘': 'å',
        'å…½': 'ç¸',
    }
    
    for old, new in corrections.items():
        text = text.replace(old, new)
    
    # å»æ‰å‰å¯¼å™ªå£°ï¼ˆä¿ç•™ä»¥ Lv. å¼€å¤´çš„ç­‰çº§æ ‡è®°ï¼‰
    if not re.match(r'^\s*Lv\.?\d+', text, flags=re.IGNORECASE):
        # å…ˆå»æ‰ä»¥ p/P+æ•°å­— å½¢å¼çš„å™ªå£°å‰ç¼€
        text = re.sub(r'^[Pp]\d+', '', text)
        # å†å»æ‰å‰å¯¼çš„ @ æˆ– çº¯æ•°å­—
        text = re.sub(r'^[@\d]+', '', text)

    # ç»Ÿä¸€å…¨è§’æ•°å­—/å­—æ¯ä¸ºåŠè§’ï¼Œå¹¶ç§»é™¤å‰å¯¼çš„é›¶ï¼ˆä¾‹å¦‚ "0çš®å¡ä¸˜" â†’ "çš®å¡ä¸˜"ï¼‰
    text = text.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï½“ï½ï¼³ï¼­', '0123456789smSM'))
    text = re.sub(r'^0+', '', text)
    
    # é‡è¦ï¼šå°†æœ«å°¾æˆ–ç©ºç™½å‰çš„ s/m ç­‰çº§åç¼€ç»Ÿä¸€ä¸ºå¤§å†™ï¼ˆé€‚é…ä¸­æ–‡+å­—æ¯ç»“å°¾ï¼‰
    text = re.sub(r's(?=$|\s|\t)', 'S', text, flags=re.IGNORECASE)
    text = re.sub(r'm(?=$|\s|\t)', 'M', text, flags=re.IGNORECASE)
    
    return text.strip()

class TransformImage:
    def __init__(self, img):
        self.img = img
    
    def extract_text_from_img(self):
        """ä»å›¾ç‰‡ä¸­æå–æ–‡å­—ï¼Œä½¿ç”¨ Free OCR API"""
        try:
            files = {"file": ("image.jpg", self.img, "image/jpeg")}
            resp = requests.post(
                OCR_ENDPOINT,
                files=files,
                data=OCR_PAYLOAD,
                timeout=30
            )
            resp.raise_for_status()
            result_json = resp.json()
            
            with st.expander("ğŸ” Free OCR API åŸå§‹è¿”å›"):
                st.json(result_json)
            
            if result_json.get("IsErroredOnProcessing"):
                st.error(f"âŒ OCR API å¤„ç†é”™è¯¯: {result_json.get('ErrorMessage', 'æœªçŸ¥é”™è¯¯')}")
                return []
            
            # æå–æ–‡æœ¬
            all_texts = []
            for entry in result_json.get("ParsedResults", []):
                text_block = entry.get("ParsedText", "")
                if text_block:
                    lines = [ln.strip() for ln in text_block.split('\n') if ln.strip()]
                    filtered = []
                    for line in lines:
                        if line in ['è¿”å›', 'ä¸»æŠ€èƒ½/å‰¯æŠ€èƒ½', 'TextOrientation', 'æ²’æœ‰æ€§æ ¼å¸¶ä¾†çš„ç‰¹è‰²']:
                            continue
                        if ':' in line and all(c.isdigit() or c == ':' for c in line):
                            continue
                        if line.startswith('Lv.') and len(line) <= 5:
                            continue
                        filtered.append(line)
                    all_texts.extend(filtered)
            
            st.write("ğŸ” OCR è¯†åˆ«åˆ°çš„æ–‡æœ¬è¡Œæ•°:", len(all_texts))
            if all_texts:
                with st.expander("ğŸ“ æŸ¥çœ‹è¯†åˆ«çš„åŸå§‹æ–‡æœ¬"):
                    st.write(all_texts)
            else:
                st.warning("âš ï¸ OCR æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬")
            
            return all_texts
        except Exception as e:
            st.error(f"âš ï¸ OCR è¯†åˆ«å¼‚å¸¸: {str(e)}")
            import traceback
            with st.expander("ğŸ› é”™è¯¯è¯¦æƒ…"):
                st.code(traceback.format_exc())
            return []
    
    def filter_text(self, result):
        """ä»æ–‡å­—åˆ—è¡¨ä¸­æå–å®å¯æ¢¦ã€æŠ€èƒ½ç­‰ä¿¡æ¯"""
        if not result:
            st.warning("âš ï¸ filter_text æ”¶åˆ°ç©ºåˆ—è¡¨")
            return {}
        
        all_texts = result if isinstance(result, list) else [result]
        info = {}
        sub_skills_found = []  # (åŸå§‹ä½ç½®, æŠ€èƒ½å) - ä¿æŒOCRè¯†åˆ«é¡ºåº
        
        # è°ƒè¯•ï¼šæ˜¾ç¤ºåŸå§‹ä¸ä¿®æ­£åçš„æ–‡æœ¬ï¼Œä¾¿äºç¡®è®¤æ¸…æ´—æ•ˆæœ
        with st.expander("ğŸ“‹ è¯†åˆ«æ–‡æœ¬ï¼ˆåŸå§‹ â†’ ä¿®æ­£ï¼‰"):
            for i, text in enumerate(all_texts):
                corrected = correct_ocr_text(text)
                st.write(f"{i}: `{text}` â†’ `{corrected}`")
        
        # ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰ä¿¡æ¯
        for i, text in enumerate(all_texts):
            if not text or not isinstance(text, str):
                continue
            
            text_corrected = correct_ocr_text(text)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ¶è¡¨ç¬¦ï¼ˆè¡¨æ ¼æ¨¡å¼ä¼šæŠŠåŒè¡Œçš„å¤šä¸ªæŠ€èƒ½ç”¨åˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰
            texts_to_check = [text_corrected]
            if '\t' in text_corrected:
                texts_to_check = [t.strip() for t in text_corrected.split('\t') if t.strip()]
            
            for text_part in texts_to_check:
                # å®å¯æ¢¦åŒ¹é…ï¼ˆä¼˜å…ˆç²¾ç¡®åŒ¹é…ï¼Œå†å°è¯•åŒ…å«åŒ¹é…ï¼‰
                if 'pokemon' not in info:
                    if text_part in pokemons_list:
                        info['pokemon'] = text_part
                    else:
                        # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼šå®å¯æ¢¦åç§°åœ¨æ–‡æœ¬ä¸­
                        for pokemon_name in pokemons_list:
                            if len(pokemon_name) >= 2 and pokemon_name in text_part:
                                info['pokemon'] = pokemon_name
                                break
                        # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œåè¿‡æ¥å°è¯•ï¼šæ–‡æœ¬åœ¨æŸä¸ªå®å¯æ¢¦åç§°ä¸­
                        if 'pokemon' not in info:
                            for pokemon_name in pokemons_list:
                                if len(text_part) >= 2 and text_part in pokemon_name:
                                    info['pokemon'] = pokemon_name
                                    break
                
                # ä¸»æŠ€èƒ½åŒ¹é…
                if text_part in main_skills_list and 'main_skill' not in info:
                    info['main_skill'] = text_part
                
                # æ€§æ ¼åŒ¹é…
                elif text_part in natures_list and 'nature' not in info:
                    info['nature'] = text_part
                
                # å‰¯æŠ€èƒ½åŒ¹é…ï¼ˆåªåœ¨ä½ç½®7ä¹‹åï¼Œä¿æŒOCRè¯†åˆ«é¡ºåºï¼‰
                elif i >= 7:
                    matched_skill = self._match_sub_skill(text_part)
                    if matched_skill:
                        sub_skills_found.append((i, matched_skill))
                        st.write(f"âœ“ åŒ¹é…å‰¯æŠ€èƒ½ï¼š`{text_part}` â†’ `{matched_skill}`")
        
        # æŒ‰OCRè¯†åˆ«é¡ºåºå¡«å……å‰¯æŠ€èƒ½ï¼ˆä¸é‡æ–°æ’åºï¼‰
        for idx, (pos, skill) in enumerate(sub_skills_found, start=1):
            if idx <= 5:
                info[f'sub_skill_{idx}'] = skill
        
        # è°ƒè¯•è¾“å‡º
        with st.expander("âœ… æå–åˆ°çš„ä¿¡æ¯"):
            st.json(info)
            if sub_skills_found:
                st.write(f"**è¯†åˆ«åˆ° {len(sub_skills_found)} ä¸ªå‰¯æŠ€èƒ½ï¼ˆæŒ‰OCRè¯†åˆ«é¡ºåºï¼‰ï¼š**")
                for idx, (pos, skill) in enumerate(sub_skills_found, start=1):
                    st.write(f"{idx}. ä½ç½®{pos}: {skill}")
            else:
                st.warning("âš ï¸ æœªè¯†åˆ«åˆ°ä»»ä½•å‰¯æŠ€èƒ½")
        
        return info
    
    def _match_sub_skill(self, text):
        """å°è¯•åŒ¹é…å‰¯æŠ€èƒ½ï¼ˆä¼˜å…ˆç²¾ç¡®åŒ¹é…ï¼‰"""
        # ç¬¬ä¸€çº§ï¼šç²¾ç¡®åŒ¹é…
        if text in sub_skills_list:
            return text
        
        # ç¬¬äºŒçº§ï¼šåŠ å‰ç¼€ç²¾ç¡®åŒ¹é…
        if f'æŒæœ‰{text}' in sub_skills_list:
            return f'æŒæœ‰{text}'
        
        # ç¬¬ä¸‰çº§ï¼šåŠ åç¼€ç²¾ç¡®åŒ¹é…ï¼ˆS/M ç­‰çº§ï¼‰
        for suffix in ['S', 'M', 's', 'm']:
            if f'{text}{suffix}' in sub_skills_list:
                return f'{text}{suffix}'
            if f'æŒæœ‰{text}{suffix}' in sub_skills_list:
                return f'æŒæœ‰{text}{suffix}'
        
        # ç¬¬å››çº§ï¼šæ¨¡ç³ŠåŒ¹é…
        for skill in sub_skills_list:
            # æ£€æŸ¥æŠ€èƒ½ååœ¨æ–‡æœ¬ä¸­
            if len(skill) >= 3 and skill in text:
                return skill
            # æ£€æŸ¥æ–‡æœ¬åœ¨æŠ€èƒ½åä¸­
            if len(text) >= 3 and text in skill:
                return skill
        
        return None
    
    def _extract_level_from_context(self, all_texts, current_index):
        """ä»ä¸Šä¸‹æ–‡ä¸­æå–ç­‰çº§"""
        level_pattern = re.compile(r'Lv\.?(\d+)', re.IGNORECASE)
        
        # æ£€æŸ¥å½“å‰è¡Œ
        if level_pattern.search(all_texts[current_index]):
            return int(level_pattern.search(all_texts[current_index]).group(1))
        
        # æ£€æŸ¥å‰5è¡Œ
        for offset in range(-1, -6, -1):
            if 0 <= current_index + offset < len(all_texts):
                match = level_pattern.search(all_texts[current_index + offset])
                if match:
                    return int(match.group(1))
        
        # æ£€æŸ¥å2è¡Œ
        for offset in range(1, 3):
            if 0 <= current_index + offset < len(all_texts):
                match = level_pattern.search(all_texts[current_index + offset])
                if match:
                    return int(match.group(1))
        
        return 999
    
    def _extract_position_from_table(self, all_texts, current_index):
        """ä»è¡¨æ ¼ç»“æ„æ¨æ–­è¡Œåˆ—ä½ç½®"""
        level_pattern = re.compile(r'Lv\.?(\d+)', re.IGNORECASE)
        
        # æ£€æŸ¥å½“å‰è¡Œæ˜¯å¦æœ‰åˆ¶è¡¨ç¬¦ï¼ˆè¡¨æ ¼æ¨¡å¼çš„æ ‡å¿—ï¼‰
        current_text = all_texts[current_index]
        has_tab = '\t' in current_text
        
        # æ”¶é›†æ‰€æœ‰ç­‰çº§æ ‡è®°çš„ä½ç½®
        level_positions = []
        for i, text in enumerate(all_texts):
            if level_pattern.search(text):
                level_positions.append(i)
        
        if not level_positions:
            return (999, 999)
        
        # æ‰¾æœ€æ¥è¿‘çš„ç­‰çº§æ ‡è®°ï¼ˆåœ¨å½“å‰è¡Œä¹‹å‰ï¼‰
        row = 0
        col = 0
        closest_level_idx = None
        
        for idx, pos in enumerate(level_positions):
            if pos < current_index:
                closest_level_idx = idx
            else:
                break
        
        if closest_level_idx is None:
            return (0, 0)
        
        # è®¡ç®—è¡Œå·
        closest_level_pos = level_positions[closest_level_idx]
        row_count = 0
        for i in range(closest_level_idx):
            # å¦‚æœç›¸é‚»ä¸¤ä¸ªç­‰çº§æ ‡è®°è·ç¦» > 2ï¼Œè¯´æ˜æ¢è¡Œäº†
            if i > 0 and level_positions[i] - level_positions[i-1] > 2:
                row_count += 1
        if closest_level_idx > 0:
            row_count += level_positions[closest_level_idx] - level_positions[closest_level_idx - 1] > 2
        
        # ç®€åŒ–ï¼šç›´æ¥æ•°æœ‰å¤šå°‘ä¸ªç­‰çº§æ ‡è®°åœ¨å½“å‰ä½ç½®ä¹‹å‰ï¼Œä¸”å®ƒä»¬ç›¸è·è¾ƒè¿œï¼ˆ>2ï¼‰
        row = 0
        for i in range(closest_level_idx):
            if i == 0 or level_positions[i] - level_positions[i-1] > 2:
                row += 1
        
        # åˆ—å·åˆ¤æ–­ï¼šå¦‚æœå½“å‰è¡Œçš„ä¸‹ä¸€ä¸ªç­‰çº§æ ‡è®°åœ¨æ¥è¿‘çš„ä½ç½®ï¼ˆ< 3 è¡Œï¼‰ï¼Œåˆ™ä¸ºå³åˆ—
        col = 0
        if closest_level_idx + 1 < len(level_positions):
            next_level_pos = level_positions[closest_level_idx + 1]
            # å¦‚æœä¸‹ä¸€ä¸ªç­‰çº§æ ‡è®°åœ¨è¿‘è·ç¦»ï¼ˆ2-3è¡Œå†…ï¼‰ï¼Œè¯´æ˜åœ¨åŒä¸€è¡Œï¼Œè¿™æ˜¯å³åˆ—
            if 0 < next_level_pos - closest_level_pos <= 3:
                col = 1
        
        return (row, col)
    
    def run(_self):
        result = _self.extract_text_from_img()
        info = _self.filter_text(result)
        print(f"{datetime.now()}: {info}")
        return info
